{"pageProps":{"posts":[{"slug":"2023-01-19-custom-steamdeck-buttons","title":"Custom SteamDeck Buttons","subtitle":"Color coded for your convenience","image":{"url":"/assets/content/blog/2023-01-19-custom-steamdeck-buttons/poster.jpg","alt":"Colorful custom action buttons on the right side of a SteamDeck held up to the camera","external":"https://foosel.net/assets/content/blog/2023-01-19-custom-steamdeck-buttons/poster.jpg"},"content":"\nMy partner and I both got ourselves SteamDecks in 2022. Since then he's repeatedly mentioned that he'd love to have\ncolored buttons on his, matching the XBox controller layout, as many PC games use these colors for their\nbutton hints during quick time events and similar. But sadly, nothing like that is available yet.\n\nWith that in mind, and after losing my initial fear about opening up the deck thanks to swapping my fan and upgrading \nmy SSD on January 1st of this year, an idea for a surprise started to form in my head. I had watched a ton of videos\non silicone molding and resin casting, I have several 3d printers at my disposal, and there was just enough time left\nin my vacation and until our anniversary to pull this off. So I went to work. In total secrecy.\n\n## Research & material collection\n\nThe first thing I jumped into was some research in order to be able to make a plan and know what to get.\n\nI ran across [this interesting thread](https://bitbuilt.net/forums/index.php?threads/resin-casting-molding-buttons.2316/)\non button casting which gave me a good idea of what I'd need in terms of materials. It also taught me that I needed to \nfigure out what kind of mold I'd even need to create for the buttons. Were they flat on the bottom in which case a single part \nmold would suffice, or were they curved or otherwise featured, in which case I'd need to create a two part mold? Instead of \ndisassembling my deck right away (too obvious with my partner being around) I decided to instead checkout \n[this excellent disassembly guide on iFixit](https://www.ifixit.com/Guide/Steam+Deck+Action+Buttons+(ABXY)+Replacement/148950)\nwhich showed me that the buttons are indeed inset on the bottom, and so I'd need a two part mold.\n\nThat in turn meant I needed to look into mold release for multi part silicone molds in addition to silicone and resin. The \nmaterial list in the thread sadly didn't help me - I couldn't get half of this stuff in Germany - but here's what I finally settled on:\n\n- **Reschimica Silicone RPRO 30** (silicone)\n- **Trollfactory Silicone Mold Separation Cream** (two part mold release)\n- **clear two part epoxy resin** (I got this from a friend who happened to have some collecting dust for several months, still sealed)\n- **food vacuumizer pump and container** (to degass silicone and resin, based on an idea from [this hackaday article](https://hackaday.com/2019/12/19/degassing-epoxy-resin-on-the-very-cheap/) - a real vaccum chamber and also a pressure pot would have been nice, but I didn't want to break the bank over a bunch of buttons here 😅)\n- **Mica powder** (to color the resin)\n- **white 4mm rub on letters** (to put the lettering on the buttons)\n- **clear UV resin** (to seal the lettering in)\n- **wooden stir sticks**\n- **plastic mixing cups**\n- **small paper mixing cups**\n- **10ml syringes** and **14g blunt needles** (for injecting the resin into the mold)\n- **plastillina clay** (to fix the buttons during the silicone pour)\n\nThanks to owning a resin printer, I already had **a UV flashlight**, **nitrile gloves** and a **respirator** on hand. \n\nAnd at least one ready to go **FDM 3d printer** for helping me in the mold creation process.\n\n![Most of the materials and tools that I used for this project, as mentioned above.](./materials.jpg)\n\n## Creating a two part silicone mold\n\nNext step was to create my two part silicone mold and for that I first needed something to fix the buttons to, do the pour for the first\npart of the mold, flip that over and create the second part of the mold. I did some more research and came across two \ninteresting videos, [\"How To Make Custom PS5 Controller Buttons\"](https://www.youtube.com/watch?v=mjKAkul-VDQ) and \n[\"Upgrade Your PS5 Controller with DIY Resin Buttons - Better than the Original!\"](https://www.youtube.com/watch?v=DfbIYH3xauc). \nIn both, EJ uses a 3d printed box with custom bottom to hold the buttons in place and create a keyed two part mold. So, I did\ncreate just that as well. My mold box consists of several parts: two halves forming the box, a bottom for the first part (creating the\nkeying), a smooth bottom and a top brace for the second part. The bottoms slot into the box halves, the top brace is just friction\nfit. Why the top brace? To hold some toothpick halves in place that create channels for resin to go in and air to go out when the\nmold is closed.\n\nI designed all this in FreeCAD[^1] and this is how it looks:\n\n![The mold box configuration for the first pour. Both halves and the keyed bottom.](./mold_case_part1.png)\n\n![The mold box configuration for the second pour. Both halves, the smooth bottom and the cross brace.](./mold_case_part2.png)\n\nYou can find the STLs [here](https://www.printables.com/model/374098-steamdeck-button-mold-case). All of the parts were printed \non my heavily modified Prusa MK3 with a 0.6mm nozzle and a 0.3mm layer height in black extrudr PLA NX2 - you might have to adjust\nthe tolerances on other printers or with other filaments, which is why I also included the FreeCAD file (which could be cleaner, \nbut it worked for me).\n\nOnce I had the mold box ready it was time to disassemble the deck and get the buttons in my hand. So I waited until my partner \nwas out of the house and then got going.\n\nFirst, I disassembled everything based on the [aforementioned iFixit guide](https://www.ifixit.com/Guide/Steam+Deck+Action+Buttons+(ABXY)+Replacement/148950). I attached the buttons to their spots on the keyed bottom plate of the mold box with some thin, rolled clay wormy \ndealies and then thoroughly cleaned them with some q-tips and isopropyl alcohol. It is important to be *very* thorough here - any\ndirt or even just a fingerprint *will* show up in the silicone mold and thus in the resin casting as well. I actually found that \nthe outlines of the letters molded into the original buttons left an impression. The level of details you can get from silicone \nmolds is astonishing! \n\nAlso make sure that you keep the lettering of the buttons oriented the same way, that way you will also\nbe able to re-use the mold later for buttons with inlayed lettering (which is my plan for version 2.0 of this project).\n\n![The four action buttons mounted to the keyed mold case bottom. My hand hovering over them with a q-tip, a bottle of isopropyl alcohol in reach. In the background the disassembled deck.](./silicone_mold_step1.jpg)\n\nI then slid the bottom plate into the grooves of the mold box halves, sealed the seam with some blue painters tape and just to be\nsafe also wrapped two rubber bands around it.\n\n![The assembled mold box for the first pour. The buttons are mounted to the bottom. The seems seasled with tape. Two rubber bands go around.](./silicone_mold_step2.jpg)\n\nNow came the time for the first pour. I weighed out 35g each of part A and B into a plastic mixing cup (my silicone gave instructions for mixing 1:1 by weight, stick to your instructions!) and then thoroughly mixed\nit with a stir stick. Then I poured that into a *second* cup, from high above, in a thin stream - this is first to get some of\nthe bubbles out but more importantly to prevent any unmixed silicone from getting into the mold. This cup I then degassed. For my\nfirst pour I actually used a power sander to vibrate the bubbles out, but for the second pour I went with the above mentioned\nfood vacuumizer - it's easier, you get way less shaky hands out of it, and the results also look better. So, into the food container, \nlid on, pump on. I degassed until bubbles stop coming out. Then I slowly poured the silicone into a corner of the mold \nbox, once again in a thin stream from up high. Take your time here, the slower, the less risk of errant bubbles making it into\nthe mold. Then I degassed the mold again for a couple minutes and let it cure based on the instructions. \n\n![The box filled with silicone after the first pour.](./silicone_mold_step3.jpg)\n\nNext, I demolded the first part by removing rubber bands and the tape around the box and then carefully pulling the two halves \napart. I then slowly removed the bottom plate from the silicone part as well, being careful to keep the buttons inside[^2]. \nI then cleaned them off of any leftover plastillina clay and any small bits of silicone.\n\n![The cured first part of the silicone mold, with the buttons still inside. The keying created by the bottom plate is visible.](./silicone_mold_step4.jpg)\n\nAfter that I placed the first part of the mold on the smooth bottom plate and slid that back into the mold box. I then applied a\ngenerous coating of two part mold release. I used an old drybrush for that and liberately spread it all across the silicone and\nbox surfaces, making extra sure to get into all the corners and creases. I taped the box seams again and then put the top brace\nin place. I broke four toothpicks in half, also broke off most of their tips, and then inserted one into each of the brace holds,\npushing into opposite ends of the buttons underneath. This was to create channels for the resin to flow into and air to push\nout of the mold.\n\n![The first part of the silicone mold placed back into the mold box. The cross brace is installed and two toothpick halves lead to each button.](./silicone_mold_step5.jpg)\n\nI once again mixed 70g of silicone from 35g of each part A and B, moved into a second cup, degassed it and slowly poured it into \nthe mold. Then that was degassed as well and left to cure.\n\n![The mold box, once again filled with silicone, and placed in the vacuum container.](./silicone_mold_step6.jpg)\n\nAnother 5h later I carefully demolded my two part mold. I once again removed tape, rubber bands and the top brace, pulling out\nthe toothpick halves in the process. I then carefully pulled the two halves of the box apart again and equally carefully peeled\nthe two parts of the mold apart from each other.[^3] I could now remove the buttons, clean them, place them back into the deck and\nreassemble it. Then I cut off some of the silicone bits that had been sucked into the internal hollow structure of the buttons\nwhich I *did* not want to replicate. I was very diligent here to not cut away too much. And then I was the proud owner of a two \npart silicone mold for SteamDeck action buttons.\n\n![The finished two part mold, visibly keyed and interlockable.](./silicone_mold_step7.jpg)\n\n## Resin time, resin time, do do do do do, resin time\n\n*Wear gloves and a respirator during this!*\n\nWith the mold now ready for action, it was time to try my hand at resin casting. I first assembled the mold, securing the two \nhalves with four rubber bands. I also attached the mold to a piece of cardboard in the process on which I noted down the location\nof each of the buttons inside the mold. This is really important to keep track of which button goes where. With everything being \nmirrored thanks to the buttons basically lying on their faces in the mold you otherwise get terribly puzzled and end up with\nbuttons of the wrong color. Ask me how I know 😅 If you get confused on which button is which, take a close look at the \nspaces they left in the mold. The B button of the deck is slightly curved on its outer side due to following the deck's case\ncurving, and that has helped me a ton to keep track of it and everything else in relation to it.\n\nNext, I mixed up 40ml of resin, so 20ml of each part A and B (my resin gave instructions for mixing 1:1 by volume, check your \ninstructions!). I degassed it in the vacuum container and then spread it across\nfour small paper cups, roughly 10ml each. I then added red, greed, blue and yellow mica powder to each of the cups, mixing that\nin thoroughly, before placing the cups into the vacuum container and degassing them again. Next, four syringes with blunt 14g\nneedles were filled with the four colors of resin and then the buttons were filled with the respective color. After getting \nconfused with the colors on my first try, I double and triple checked each color before filling it in on the second. I carefully inserted\nthe needle into the inner channel and then slowly pressed the resin in until it came out of the outer channel. On my first\ntry I made the mistake to overfill, which caused some unintentional color mixing, so be sure to really stop right when the \nresin comes out of the air channel. \n\n![The button mold filled with the colored resin, the four small paper cups holding the unused resin sitting next to it in an aluminium tray.](./resin_cast_step1.jpg)\n\nI then let the buttons cure for 24h before taking a first peek. \n\n![The buttons after 24h of curing.](./resin_cast_step2.jpg)\n\nThey looked great, but a quick fingernail test on one of the resin pots showed the stuff was not fully hardened yet. It turned \nout to take 72h until I could proceed with the finishing steps.\n\n## Finishing the buttons\n\nI kept the buttons attached to the mold for the final steps, as that helped a lot with keeping everything aligned and\nless fiddly (it was fiddly enough as is). I carefully placed the sheet with rub on lettering I had bought over each button,\nmaking sure to center the corresponding letter. Then I rubbed the letter on using the blunt tip of my letter opener. The stuff\ndidn't want to stick to the smooth top surface very well, which had the upside of allowing me to redo something if I messed up, but also\nthe downside of me having to be *very* careful to not mess things up that were already fine. In the end, it took me some tries\nbut I prevailed.\n\nThen I got out the UV resin, put on the respirator and gloves, and with an old brush softly brushed on a thin layer of\nresin on each button, careful not get any drops on the side or pooling, but sealing in the letter. I then cured that for several minutes\nwith the UV flashlight.\n\nOnce the resin was cured I carefully pulled out the buttons from the mold and then cut off the sprue with a flush cutter.\n\n![The four custom buttons sitting on a post-it note.](./finished_buttons1.jpg)\n\nA quick test fit in my deck showed that I needed some light sanding on one side of X, but that was quickly taken care of and\nthen I had a working set of custom SteamDeck buttons 👍\n\n![Colorful custom action buttons on the right side of a SteamDeck held up to the camera.](./finished_buttons2.jpg)\n\n## Where do we go from here?\n\nConsidering that until Monday January 9th 2023 I had never before touched silicone or epoxy resin, and that by Monday January 16th 2023 I had four self-cast SteamDeck buttons in my hand that while far from perfect looked *great*, I'm *very*\nhappy with the result. And the same goes for my partner, who really had absolutely no idea of this until I presented him the\nfinished buttons on our anniversary. He was and is in awe 😊\n\nHowever, single colored buttons with rubbed on letters sealed in with UV resin is not my end goal here. After seeing the amazing results one can\nachieve with inlaying in EJ's videos, I'm really looking forward to trying that out. So the next step will be to cast some inlayed buttons\nwith the same mold. And I have already printed out the letters on my resin printer 😁\n\n[^1]: To be more precise, FreeCAD Link Branch version 2022.09.07\n[^2]: If one of the buttons slips out of the mold, you can just press it back in. Just make sure it really slots right back in\nwhere it was, same orientation, full depth and everything. I actually had to do this a bunch of times due to the mold making \nstretching over several days due to some issues (see next footnote), and having to reassemble the deck in between to keep\nthe project a secret from my partner. As a consequence, I can now disassemble and reassemble the deck down to the buttons in\naround 20min without the guide 😄\n[^3]: I actually had to do the second pour thrice: The first time I didn't create the channels with toothpicks, thinking I could \npunch them out afterwards - I couldn't. That led to the creation of the top brace. I then made the mistake to further secure the \ntoothpicks with superglue, which seems to have interacted with the curing process and caused the top layer of the silicone pour \nto stay soft, smeary and sticky. So I did it a third time, exactly as described above, just relying on the friction fit of the\ntoothpicks, and this time everything cured as expected and I had usable channels 😅\n","excerpt":"","published":"2023-01-19T00:00:00Z","readingtime":{"text":"15 min read","minutes":14.25,"time":855000,"words":2850}},{"slug":"2022-01-03-tfa-dostmann-meets-esphome","title":"TFA Dostmann meets ESPHome","subtitle":"Integrating a CO2 sensor into my HA setup","image":{"url":"/assets/content/blog/2022-01-03-tfa-dostmann-meets-esphome/tfa-dostmann-front.jpg","alt":"A TFA Dostmann CO2 sensor","external":"https://foosel.net/assets/content/blog/2022-01-03-tfa-dostmann-meets-esphome/tfa-dostmann-front.jpg"},"content":"\nI attended RC3 from December 27th until December 30th. While it was (once again)\nonly a virtual edition of the Chaos Communication Congress, at least this time\naround I managed to have a similar experience to 36c3, as in, I spent the last two days\nmostly hanging out with a bunch of fellow geeks in a fun location (a jitsi conference\nthat also included a camera pointing at an aquarium full of fish) and nerding out\nwhile tinkering around with electronics.\n\nAnd thus I finally integrated the CO2 sensor unit I bought a couple weeks ago into\nmy Home Automation setup, with the help of a Wemos D1 Mini and [ESPHome](https://esphome.io). At first\nI went with an ESP12, a voltage regulator and a [different firmware](https://github.com/schinken/esp8266-co2monitor),\nbut that didn't work out due to the ESP not wanting to behave (my guess is I didn't wire the barebone module\nup correctly or the voltage regulator was causing issues) and I also got some weird readings \nreported by the firmware (20k ppm CO2 - I know the air in my office can get bad after a couple of hours of\ncoding, but not THAT bad).\n\nThe CO2 sensor is an \"AIRCO2NTROL MINI\" from TFA Dostmann, but it is also available under other names\nwith a very similar case and more or less the same internals, as I learned from the\n[ESPHome docs](https://esphome.io/components/sensor/zyaura.html). Where my Dostmann edition seems to differ from the majority is the\npin order of the internal debug port, which turned out to have CLK and DATA swapped\nin my case, which caused me quite the headache and a bit of frustration. So just for future reference,\nthe pin order I found in my device is 5V - Data - CLK - Gnd from left to right with the hose to the left:\n\n![The pinout of the sensor's debug port, 5V - Data - CLK - Gnd](./tfa-dostmann-pinout.jpg)\n\nI hooked these up to the Wemos D1 Mini (clone) like this:\n\n![A wiring diagram of how to hookup the Wemos D1 mini to the debug port, 5V to 5V, Gnd to Gnd, Data to D1 and CLK to D2](./tfa-dostmann-wemos-d1-wiring.png)\n\nSo 5V to 5V, Gnd to Gnd, Data to D1 and CLK to D2.\n\nThe ESPHome config I then flashed to the D1 is the following:\n\n``` yaml\nesphome:\n  name: dostmann-office\n  platform: ESP8266\n  board: d1_mini\n\nlogger:\n\nmqtt:\n  broker: !secret mqtt_iot_broker\n\nota:\n  password: !secret ota_pass\n\nwifi:\n  ssid: !secret wifi_iot_ssid\n  password: !secret wifi_iot_pass\n  ap:\n    ssid: \"Dostmann Office Fallback\"\n    password: !secret fallback_pass\n  power_save_mode: high\n\ncaptive_portal:\n\nsensor:\n  - platform: zyaura\n    clock_pin: D2\n    data_pin: D1\n    co2:\n      name: \"Office Dostmann CO2\"\n    temperature:\n      name: \"Office Dostmann Temperature\"\n\n  - platform: wifi_signal\n    name: \"Office Dostmann WiFi Signal\"\n    update_interval: 60s\n```\n\n(If you are wondering about the `!secret` stuff, those values are contained in \na `secret.yaml` file in my esphome folder, and you can read all about that\n[in the ESPHome docs here](https://esphome.io/guides/faq.html#tips-for-using-esphome).)\n\nAnd with that I could now see the sensor in my Home Assistant instance and forward the data\neasily to my InfluxDB & Grafana monitoring stack.\n\nTo put everything together physically, fully contained, I used [this alternative backplate](https://www.thingiverse.com/thing:4225732)\nby Stefan Kern. \n\n![The alternative backplate in place, closing up the sensor and containing the Wemos D1 Mini as well](./tfa-dostmann-back.jpg)\n\nHowever, I've noticed a temperature increase of around 3°C with it and the ESP\nin place, and I fear this might be screwing with the CO2 sensor's calibration (as the measurement\nis temperature sensitive). I already mitigated this a bit by setting the chip to power save and adding some strategically placed aluminium tape,\nbut that's only improved things slightly. Due to that I plan to redesign the \nbackplate to have the ESP outside the sensor case, in its own compartment. I \nhope that will solve the \"running hot\" issue for good then, but we'll see.\n\n*Update from January 27th 2022* I redesigned the backplate and now have a solution that seems to work better, based on the reported temperature and CO2. [I've published it here](https://www.prusaprinters.org/prints/119968-airco2ntrol-mini-backplate-with-wemos-d1-mini).\n\nIn any case, for now I at least got a reliable indicator of my office's CO2 levels that also now\nare trackable long term, and I have also forwarded the current values to my [AWTRIX mini](https://awtrixdocs.blueforcer.de/)\nvia some NodeRED flow that also takes care of color coding. Further possibilities include\nflashing the office lights or some audio cues, should just the visual warning turn out\nto be insufficient in the long term 😉\n\n![CO2 sensor data graphed over two days](./grafana-co2.png)\n","excerpt":"","published":"2022-01-03T00:00:00Z","readingtime":{"text":"4 min read","minutes":3.715,"time":222900,"words":743}},{"slug":"2021-09-28-being-patient-with-yourself-is-hard","title":"Being patient with yourself is hard","subtitle":"What a knee surgery taught me about myself","image":{"url":"/assets/content/blog/2021-09-28-being-patient-with-yourself-is-hard/poster.jpg","alt":"Two crutches leaning on a couch","external":"https://foosel.net/assets/content/blog/2021-09-28-being-patient-with-yourself-is-hard/poster.jpg"},"content":"\nI've been having knee issues all my life. I can't remember a time when the occasional pain, stiffness and crunchy noises in both knees weren't part of my regular experience. The past three years however the left knee got a ton worse, frequently hurting for days on end, getting hot, and overall just being a literal pain. That is why earlier this year I finally decided, enough is enough, got another opinion from my orthopedist and we scheduled a key hole surgery to fix what was suspected to be a very active plica syndrome. This surgery happened on September 20th and it made me learn a LOT about myself.\n\nI went into this knowing that I'd be immobilised for a few days, that I'd need crutches, that there'd be pain and also several weeks of physical therapy following the surgery. What I did not expect was how *utterly* impatient I would be with myself.\n\nSee, this was the first surgery I ever had as a conscious person. I did have two minor ear surgeries as a toddler, at two and four years of age, and while both of them make for my earliest (and quite scary) memories, I don't have any feeling on how long recovery took, what it entailed and so on. And in any case, that wouldn't have allowed me to judge what I was looking at with a knee surgery anyhow. I had read up on this of course. How I could expect full weight bearing of my leg by day two or three, and how I was even encouraged to try to really use it again right after. That there would be some swelling for a few days. In my mind this resulted in \"I'll be back on my feet with everything working in no time\".\n\nColour me surprised when I woke up from anesthesia to a ridiculous amount of pain, the inability to lift the leg, swelling beyond expectation and the information that there had been a so far undetected meniscus tear that had since scarred over. And thus began a journey of self discovery 😅\n\nWhat this experience taught me has been eye opening. It turns out I have next to no patience with myself. Consciously I understood that the knee would need time to recover, that the swelling would not come down one day to the next and that I'd have to give myself time to heal. But at the back of my head almost immediately I started judging myself and falling short of my expectations. Here I am, a week post surgery, and feeling bad for still preferring to have my crutches in reach even though the leg is fully weight bearing again simply because walking without them feels utterly unstable and outright hurts too after one too many attempts at pushing myself. Here I am fretting over the inability to achieve full motion in the leg again even though it has gotten better day after day and I have been taking small milestones all the time. And here I am growing increasingly annoyed by my general reliance on help.\n\nThis surgery made me discover a new flaw for good that I had suspected to be there for a long time. I'm utterly impatient with myself. I have absolutely no problem with other people taking all the time they need to recover, to heal, to work through a problem, but when it comes to myself I have such high expectations that I'm absolutely bound to fail them and get frustrated by that. I've pushed myself through bad times before - my mental health did not thank me but yielded and I made it work somehow. My body however is **not** taking this kind of crap from me and showing me some *strong* boundaries right now, and that is an utterly humbling learning experience.\n\nI wouldn't say you should get yourself a knee surgery, because frankly this experience so far sucks a lot. But if you do, take it as a chance to practice patience with yourself. It's what I'm now seeing myself forced to do and it was long overdue.\n","excerpt":"","published":"2021-09-28T00:00:00Z","readingtime":{"text":"4 min read","minutes":3.44,"time":206400,"words":688}},{"slug":"2021-09-12-hydroponics-the-kratky-way","title":"Hydroponics the Kratky way","subtitle":"How I found myself with way too much Basil on my hands","image":{"url":"/assets/content/blog/2021-09-12-hydroponics-the-kratky-way/poster.jpg","alt":"My two Kratky grown Basil plants, next to the two Kratky grown Oregano plants","external":"https://foosel.net/assets/content/blog/2021-09-12-hydroponics-the-kratky-way/poster.jpg"},"content":"\nSince my partner loves spicy food, earlier this year I got us a chili growing kit. What was meant as an experiment has since become a full blown pepper growing operation that has taken over my livingroom window sills and half the balcony and already yielded its first fruits. And because whenever I try something new I also tend to do way too much research on it, while getting the plants started the normal way in soil (and then promptly running into the first issues with fungus gnats) I started to look deeper into [hydroponics](https://en.wikipedia.org/wiki/Hydroponics). \n\nI had heard of this approach before: growing plants in an inert grow medium instead of soil and feeding them with controlled nutrient solutions pumped around the roots. It's a fascinating rabbit hole to go down and it always tickled my interest (especially given the automation and sensoric evaluation possibilities), however it also felt way too involved to get started with unless I had some more actual space and some actual need to grow plants, what with all the lights and pumps and pipe systems that I saw associated with it. That is, until I came across the [Kratky method](https://en.wikipedia.org/wiki/Kratky_method).\n\nThe Kratky method is a pretty much passive approach to hydroponics. The idea is simple: you take an opaque container for your nutrient solution, cut a bunch of holes in the lid and then place your plants into netpots or similar in those holes so their roots reach into the solution. So far, so similar to the [Deep Water Culture](https://en.wikipedia.org/wiki/Deep_water_culture) approach. But instead of now aerating the solution with an aquarium air stone or similar to give your roots the oxygen they need, you instead simply allow the level of your nutrient solution to drop, creating an air gap and leaving parts of the roots hanging in the air. That way the roots can get nutrients but can also breathe (which is important so they don't rot). You'll have to fill up the solution a bit if needed (always leaving an airgap), but apart from that the whole setup is completely self managed. No power needed, no moving parts. And easily set up in something as small as a mason jar.\n\nThis was intriguing to me, and I had wanted to try my luck with growing some basil and oregano for pizza and such anyhow, so I decided to give this approach a shot. I ordered a kitchen herb seed kit, some 1l mason jars, some rock wool cubes (as growing substrate) and some hydroponic fertilizer. Then I fired up FreeCAD and designed a small lid with integrated rock wool cube holder (STL [here](https://foosel.net/files/kratky/quattro_stagioni_kratky_1l_36mm.v2.stl), FreeCAD file [here](https://foosel.net/files/kratky/quattro_stagioni_kratky_1l.FCStd)), printed a bunch of them and then went to work.\n\n![The lid design with rock wool cube holder in FreeCAD](./lid-design.png)\n\nThe seeds were planted in the rock wool cubes, watered and then I waited. The first green soon showed up and thus I transferred the cubes into their holders, filled the jars with 1l water plus the recommended fertilizer amount (thus creating a nutrient solution) and then put the lids on. The cubes sat right in the solution and thus were kept watered. To keep light out of the container (to prevent algae growth and also to not have everything heat up so much) I simply wrapped some aluminium foil around the jars. If I'm honest this was just meant as a temporary solution until I got around to sewing a little cover out of some light blocking fabric I have on hand, but I still haven't gotten around to do that and the foil works just fine 🤷‍♀️\n\n![The two baby Basil plants at the start of their Krakty journey](./start.jpg)\n\nThat was on July 18th and since then I've been able to witness some astonishing growth, especially on the Basil. Have a look at the progress: \n\n![Progress on July 27th, the two plants are around 5cm high.](./progress-07-27.jpg)\n\n![Progress on August 4th, around 12-15cm high.](./progress-08-04.jpg)\n\n![Progress on August 14th, around 20-25cm in height.](./progress-08-14.jpg)\n\n![Progress on August 27th, more than 30cm high.](./progress-08-27.jpg)\n\n![Progress on September 10th, the plants are now around 50cm height each.](./progress-09-10.jpg)\n\nAs of today, both Basil plants had reached a plant height of around 50cm. The Oregano also looks healthy, but sadly I accidentally got hold of a hanging variant, making everything a bit tricky in this setup 😅\n\nSadly, I had to emergency-harvest one of the Basil's today. While topping up the nutrient solution the other day I noticed the roots to be way darker than they should be. They didn't look particularly healthy. Some of the leaves also started to look a tad unhappy. I came to the conclusion that I might have caught myself some root rot on this plant. Doing some research I learned that with the Kratky method, if you grow for longer than 4-6 weeks you really should occasionally replace the nutrient solution completely and clean the container to keep bacteria from taking root in your roots (pun not intended). I guess this is what happened here. I tried to save the plant with a 2:1 water and 3% hydrogen peroxide bath yesterday, but either it was already too late or that was too much stress. This morning the leaves were hanging and the whole plant looked quite sorry so I decided it was time to harvest and now I have a jar of fresh pesto verde. \n\n![One small jar of freshly made pesto](./pesto.jpg)\n\nFurther reading revealed that it's apparently an option to add a teeny tiny amount of 3% hydrogen peroxide to the nutrient solution itself to help keep any unwelcome guests away (and also help with aeration), so I've now added 0.5ml to my freshly topped off jar of the other Basil and hope that won't do harm but rather good. Wish me luck 😉\n\nAll in all, I call this whole first dabbling with hydroponics a great success. The Kratky method allowed me to get up and running quickly without huge investments and space requirements, and the results were amazing. I've also now planted some peppermint seeds and they are already sprouting, so my hopes are high for some amazing fresh teas later this fall! If you've always wanted to experiment with hydroponics but it always felt way too involved, maybe take a look at the Kratky method 😊\n","excerpt":"","published":"2021-09-12T00:00:00Z","readingtime":{"text":"6 min read","minutes":5.26,"time":315600,"words":1052}},{"slug":"2021-05-09-a-debugging-story","title":"A debugging story","subtitle":"Could this bug for once not be my fault?","image":{"url":"/assets/content/blog/2021-05-09-a-debugging-story/issue_4117.png","alt":"The screenshot showing the issue -- a rendering defect in OctoPrint's GCode viewer","external":"https://foosel.net/assets/content/blog/2021-05-09-a-debugging-story/issue_4117.png"},"content":"\nAbout a week ago I got a new [bug report](https://github.com/OctoPrint/OctoPrint/issues/4117) on [OctoPrint's](https://octoprint.org) issue tracker:\n\n> **GCode Viewer Visualisation Problem**\n>\n> *The problem*\n> \n> The visualisation in GCode viewer ist not correct. The print is OK.\n> See gcode file (zip) on Layer 43 to 47 and 49\n>\n> And screenshot\n\nYou already saw the included screenshot, and it shows that there was a spike being visualized in the GCode Viewer that\nwasn't actually there. My first attempt at reproduction failed spectacularly -- the file looked exactly like\nit was supposed to. Then I noticed that the OP was using Google Chrome however (adding the detected user agent\nto the system information contained in OctoPrint's new System Info Bundles already paid off!) and tried with that\ninstead of my usual Firefox, and lo and behold, I saw the issue.\n\nScrolling a bit through the file revealed further defects, as also mentioned by the OP, e.g. this one:\n\n![Another defect, this time a whole part of the outline is being misplaced](./issue_4117_2.png)\n\nAt this point it was clear that this was a Chrome-only issue. But was it a bug in OctoPrint or possibly a browser \nbug? More information for that was needed but not readily available, and the file was also too big to quickly\ngleam anything from the GCode itself that could possibly help to narrow down on the problem. \n\nSo the first step was to create a minimal GCode file that showed the same error. For this I took a look at \nthe reported layer height in the viewer on the layer a defect was visible and then narrowed down on the affected lines\nby using the horizontal command sliders to further limit the view. That way I quickly found that these were the \nproblematic lines:\n\n``` gcode\nG1 X173.595 Y103.9 E247.16716\nG3 X173.600 Y126.097 I-105613.507 J39.645 E248.20080\nG1 X169.552 Y126.098 E248.38933\n```\n\nMore specifically, the error was caused by the contained [`G3` command](https://reprap.org/wiki/G-code#G2_.26_G3:_Controlled_Arc_Move), \nwhich instructs the printer to move in a counter clockwise arc\nfrom its current position to the given X and Y coordinates, with the center of said arc offset by the given I and J\nparameters. In the case of these lines, that meant to move in an arc from `(173.595, 103.0)` to `(173.600, 126.097)`\nwith the arc's center at `x = 173.595 + (-105613.507) = -105439.912` and `y = 103.9 + 39.645 = 143.54500000000002`. \nOr in other words, a rather short arc with an enormous radius of over 105m that was more a straight line than\nan arc really. And that line was being drawn too long, causing the weird spike in the rendition.\n\nIn order to understand how that could happen however we need to take a look at how the GCode viewer is implemented and how\narcs work in that implementation. At its core, the GCode viewer is an HTML5 2D canvas on which the path described in \na GCode file gets drawn. Commands like `G0` and `G1` that describe straight lines are drawn using [`lineTo`](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/lineTo),\narcs as described by `G2` and `G3` are drawn using [`arc`](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/arc).\n\n`arc` takes six parameters: the `x` and `y` coordinate of the center of the arc, the radius `r`, the `startAngle` determining from which angle to start\ndrawing the arc and the `endAngle` until which to draw the arc, and a flag that's `true` for counter clockwise and `false` or empty for clockwise.\nIt is obvious this doesn't directly translate to the data contained in the GCode itself, where we rather have three points defining the arc -- a start\npoint, and end point, and the arc's center. So we need to translate this into the data required by the `arc` method. Using some trigonometry,\nthat is fairly straightforward:\n\n``` js\n// given: G2/G3 X<endX> Y<endY> I<i> J<j>, <startX>, <startY>\narcX = startX + i;\narcY = startY + j;\nr = Math.sqrt(i * i + j * j);\nstartAngle = Math.atan2(startY - arcY, startX - arcX);\nendAngle = Math.atan2(endY - arcY, endX - arcX);\nccw = (command === \"G3\")\n```\n\n![The parameters and their relation](./drawing.png)\n\nMy first guess was that the result of this conversion was somehow different between Firefox and Chrome, and so I modified the GCode viewer to log\nthe calculated values and then compared the two outcomes. The values were completely identical between both browsers, so what was being fed\ninto the canvas `arc` command was identical and yet produces different results. Why?\n\nMy next approach was to add some more visual debug output to the viewer itself. I modified it such that the arc parameters as calculated would \nactually be drawn on the canvas as well, in form of a geometrical pizza slice showing the arc's center, its \"legs\" and its rim. And this is where\nI saw a difference in the rendered output. Where in Firefox the arc's rim and its legs met perfectly:\n\n![The arc in Firefox is rendered correctly](./arc_ff.png)\n\nin Chrome the rim overshot:\n\n![The same arc in Chrome is rendered wrong](./arc_chrome.png)\n\nSo while the calculated parameters were correct and in both cases provided to the `arc` method just the same, Chrome was rendering the wrong segment length! \n\nI suspected a rounding error and thus started searching for matching reports from other people. I couldn't find a specific bug report, but I came across a post on Stack Overflow that sounded mightily familiar: [HTML5 canvas arcs not rendering correctly in Google Chrome](https://stackoverflow.com/questions/8603656/html5-canvas-arcs-not-rendering-correctly-in-google-chrome), from 2011. A ten year old post... could it be?\n\nHonestly, I still do not know if this indeed described the same issue or not, or if there's a Chrome ticket describing this behaviour -- I'll continue to look, but first and foremost I was focused on fixing this problem in OctoPrint's GCode viewer. The Stack Overflow post provided a code snippet that reimplements `arc` utilizing bezier curves, and so I gave this a try. Long story short, OctoPrint's GCode Viewer as part of version 1.7.0+ will ship with a Chrome-only `arc` replacement that will be enabled by default, but can also be disabled in real time, with great effect:\n\n![Enabling and disabling the arc workaround makes the defects disappear and reappear](./arc_fix.gif)\n\nAnd the moral of the story: It rarely is a browser bug. But sometimes, all signs say it indeed *is* and a workaround is the easiest solution.\n","excerpt":"","published":"2021-05-09T00:00:00Z","readingtime":{"text":"6 min read","minutes":5.27,"time":316200,"words":1054}},{"slug":"2021-03-28-homelab-uplink-monitoring","title":"Homelab uplink monitoring","subtitle":"Keeping an eye on my ISP's performance","image":{"url":"/assets/content/blog/2021-03-28-homelab-uplink-monitoring/title.png","alt":"My networking dashboard in Grafana with speed and latency monitoring","external":"https://foosel.net/assets/content/blog/2021-03-28-homelab-uplink-monitoring/title.png"},"content":"\nFor a bit more than two years now I've been closely monitoring my network uplink. In the past I had a ton of issues with up- or download speeds not being what I paid for, packet loss issues and outright full blown outages. In order to put myself into a better position when reaching out to the ISP's support hotline I figured it would be good to be able to proof not only the existence of these issues but to also be able to determine the exact times they happened at and also to verify and show that in fact it was only external connections that were suffering and it was not an issue with my own internal network. Given that I don't trust the cable modem/router they force on me to be my edge router and instead have my own Unifi gear set up behind it (considering anything not exclusively under my control to be part of the hostile public internet) this otherwise will usually lead to endless attempts to blame my LAN when in fact the issue lies outside of my reach.\n\nI already had an [InfluxDB](https://www.influxdata.com/) and [Grafana](https://grafana.com/) setup running anyhow for my [Home Assistant instance](https://home-assistant.io/) to dump values from my home climate sensors into, so it was a logical next step to simply add some additional sensors to the mix.\n\n## Throughput\n\nI currently run a speed test of the network throughput every 20min and log the results via MQTT into InfluxDB. I had to find out that neither the speed test integration in Home Assistant nor the official speedtest-cli tool were performing reliably enough for this -- I was constantly getting dips in measured throughput and thus alerts, even when everything was completely fine with my uplink.\n\nI solved this by turning to [speedtest-rs](https://github.com/nelsonjchen/speedtest-rs) and a small shell script that parses the output and pushes it into MQTT to Home Assistant, which then processes it further for some visualization right on my dashboard but also forwards it further into InfluxDB. You can find the `Dockerfile` and the script plus some further info [in this gist](https://gist.github.com/foosel/ef98a5774d1a495ab3781eba8a157fee).\n\nIn Grafana I then use this data to provide me with some single stat panels for the current downstream, upstream and ping values as well as the averages over the selected time range:\n\n![Some single stat panels show current and average down- and upstream speed and measured ping](./currentspeed.png)\n\nAdditionally, I also plot the down- and upstream speed in a timeline, together with the current bandwidth consumption as extracted by Home Assistant from my ISP's cable modem/router (thanks to the [Fritzbox NetMonitor integration](https://www.home-assistant.io/integrations/fritzbox_netmonitor/)). Together, this gives me a good picture of whether there is actually an issue when I see a dip in the measured values, or if it's just too high bandwidth utilization:\n\n![A graph showing measured up- and downstream speed vs consumed up- and downstream bandwidth utilization](./bandwidth.png)\n\nYou can see in these screenshots that I recently upgraded my plan with my ISP -- from 200/20 to 500/50 MBit. The problem: The speedtest run by my monitoring setup doesn't hit the 500 mark, whereas running a manual test on speedtest.net works just fine. Looking at the `speedtest-rs` README it becomes apparent that this is a known issue with the legacy (open) Speedtest.net API:\n\n> This tool currently only supports [HTTP Legacy Fallback](http://www.ookla.com/support/a84541858) for testing.\n>\n> High bandwidth connections higher than ~200Mbps may return incorrect results!\n>\n> The testing operations are different from socket versions of tools connecting to speedtest.net infrastructure. In the many FOSS Go versions, tests are done to find an amount of data that can run for a default of 3 seconds over some TCP connection. In particular, `speedtest-cli` and `speedtest-rs` tests with what Ookla calls the [\"HTTP Legacy Fallback\"](http://www.ookla.com/support/a84541858) for hosts that cannot establish a direct TCP connection.\n\nI fear I might have to look into reimplementing the current speedtest-to-mqtt setup with another container utilizing the official (and sadly proprietary) Speedtest CLI tool to mitigate this issue. Thankfully, it should be quite easy to build a drop-in replacement thanks to the modularization in effect.\n\n_Update from March 30th 2021_ I've now done that and [here's an updated gist](https://gist.github.com/foosel/70ecbeade55cc852dbc0a4f7c4040adc) that works identically to the `speedtest-rs` approach, but instead utilizes [Ookla's official command line tool](https://www.speedtest.net/apps/cli). The results are stable numbers that reflect the expected bandwidth and also match the web based test results.\n\n_Update from March 31st, 2021_ I wasn't too happy with running a proprietary tool for my speed testing, went looking for an OSS alternative, came across [librespeed](https://librespeed.org/) and therefore have now [replicated the setup again using that](https://gist.github.com/foosel/f7d9a08c0445454ab90d6c4974a9e316). You might want to experiment a bit to find a server close to you and define that via `--server <id>`, the auto discovery appears to be a bit wonky. Or just use your own server list via `--server-json` or `--local-json`.\n\n## Latency and packet loss\n\nIn addition to the available up- and downstream speeds, I constantly monitor latency and packet loss to a selected number of hosts both external and internal to my network as well. For this I ping some public DNS servers (Google, Cloudflare and Quadnine) and some of my own vservers for the remote side, and the ISP's Fritzbox, my managed network gear and internal servers for the LAN side. I used to do this via [Smokeping](https://oss.oetiker.ch/smokeping/), but when I set up my InfluxDB/Grafana stack I wanted to find a solution to have everything together in one place.\n\nThankfully I almost immediately found [this post by Tor Hveem](https://hveem.no/visualizing-latency-variance-with-grafana) who solved this with a little custom Go tool to run `fping` against a number of configurable hosts and push the results right into InfluxDB. This was exactly what I wanted and thus I replicated the outlined setup, albeit with a slightly different color scheme.\n\nI use a [modified version of Tor's `infping` tool maintained by Nick Van Wiggeren](https://github.com/nickvanw/infping) and run that in a Docker container on my NAS. You can find everything needed to run this on your own [in this gist](https://gist.github.com/foosel/46804306d510d79f14117f95ed64b877).\n\nAs a result I get ping output for all hosts every 60 sec with times and packet loss information pushed right into InfluxDB. This is easily queried by Grafana and looks quite nice when visualized:\n\n![A graph showing min, avg and max latency and packet loss data for 8.8.8.8](./smokeping.png)\n\nAnd on my network dashboard, I plot only the `avg` values across all hosts and a mean `loss` value into one single graph each for external and internal hosts:\n\n![A graph showing avg latency and packet loss data for all remote hosts](./latency.png)\n\nThis allows me a good overview of the current state of uplink and internal network at one glance.\n\n## Alerts\n\nSince just graphs won't give me an immediate heads-up when something goes wrong, I have a bunch of alerts set up in Grafana:\n\n-   Measured download speed falls beneath 250MBit for more than one hour\n-   Measured upload speed falls beneath 35MBit for more than one hour\n-   Mean packet loss across all external hosts rises above 25% for more than ten minutes\n\nAll of those trigger a notification to a private Discord server (via Grafana's own notification mechanism). In theory this notification should even include a screenshot of the panel for which the alert was triggered for, but I'm having some problems with that still that I need to investigate.\n\n![An example alert and alert clearance notification in Discord](./discord.png)\n\nThis notification channel has an obvious problem: When the uplink goes out completely, I won't get the notification if my phone is in my LAN. I really need to add a local alert as well at some point 😅\n\nStill, it usually will give me a heads-up in time for me to reach out to my ISP on short notice and request they start troubleshooting.\n\n## Conclusion\n\nThis monitoring setup has proven valuable in debugging network performance issues and also getting an early heads-up about current ISP issues. I have successfully used screenshots for proving ongoing issues to my ISP, and also sped up the one or other troubleshooting session when there was in fact an issue with my LAN. In my book, that makes it absolutely worth the time it took me to set this up and maintain it. And: it kinda looks cool 😎\n\nIf you want to give this a go yourself, this might be of interest to you:\n\n-   [Dockerfile, compose and instructions for speedtest container](https://gist.github.com/foosel/f7d9a08c0445454ab90d6c4974a9e316)\n    -   [Ookla speedtest based version](https://gist.github.com/foosel/70ecbeade55cc852dbc0a4f7c4040adc)\n    -   [speedtest-rs based version](https://gist.github.com/foosel/ef98a5774d1a495ab3781eba8a157fee)\n-   [Dockerfile, compose and instructions for infping container](https://gist.github.com/foosel/46804306d510d79f14117f95ed64b877)\n-   [Panel JSON for the mentioned visualizations](https://gist.github.com/foosel/ec0b6355d1d0c3ab65ee4df79d795a73)\n","excerpt":"","published":"2021-03-28T00:00:00Z","readingtime":{"text":"8 min read","minutes":7.11,"time":426600,"words":1422}},{"slug":"2021-03-19-on-wrong-assumptions","title":"On wrong assumptions","subtitle":"How I once spent two weeks barking up the wrong tree","image":{"url":"/assets/content/blog/2021-03-19-on-wrong-assumptions/screenshot.jpg","alt":"A shot of the screen displaying the diff of the fix","external":"https://foosel.net/assets/content/blog/2021-03-19-on-wrong-assumptions/screenshot.jpg"},"content":"\n*The original version of this post was published as a [Twitter thread on March 23rd 2020](https://twitter.com/foosel/status/1242121324438355974). I figured I should give it a more permanent home here since IMHO it was a quite fun story.*\n\nSince everyone can use some entertainment right now, how about a battle story on how a year ago I spent almost two weeks trying to wrap my head around a really weird issue of a lagging GCODE viewer and overall print progress reporting in [OctoPrint](https://octoprint.org) and finally figuring it out?\n\nOur story begins around the release of 1.4.0, when [a new topic on the community forum](https://community.octoprint.org/t/curious-issue-with-print-progress/16304) showed up:\n\n> ### Curious issue with print progress \n>\n> The print progress figures on my Octopi setup are lagging behind the actual print. [...] Nothing is broken - anything I throw at it (an Ender 3) prints fine but as a print progresses, the percentage complete, current layer, and sync'd gcode viewer gradually lag behind what is actually being printed. For example, on a print with 400 layers, as the last layer is printed the reported progress and current layer is around 96% and 385 respectively. If I do a quick calculation of the displayed Printed/Total file size figures it works out at 96% but what it has actually printed is over 99%. When the print finishes the numbers jump to 100% and 400 and everything is fine.\n>\n> [...]\n\nThis was indeed a very curious issue, since due to the nature of the communication with the printer and buffering in the firmware the progress is usually rather slightly *ahead* than behind. Some quick testing on my end showed no reproduction, however more and more people chimed in with the same observation. \n\nI was stumped.\n\nMy first approach was to collect information from those affected by it. Printer model, firmware version, installed plugins, used slicer and so on. It soon turned out that all affected installations were using Ultimaker Cura as the slicer.\n\nA quick test by the OP with a different slicer confirmed that it indeed just occurred with GCODE sliced by Cura for him, same file in another slicer had everything work as designed. However, comparing the GCODE revealed no immediate differences that would explain this, and what actually is *in* the file also doesn't really play into progress tracking. My own experiments with Cura failed to reproduce.\n\nConvinced that the issue must be some sort of delay between the backend and the frontend -- maybe due to network issues? -- I whipped up a plugin (since deleted) to log progress on both ends to a log which could then be shared and analysed. The first results came in an guess what? I had barked up the wrong tree, the reported progress was identical. So back to square one.\n\nI still couldn't reproduce it on my end and was starting to get really angry at this issue 😅 I finally threw a copy of some GCODE files now shared by the reporter of the issue on my own printer and *finally* I could reproduce. Which doesn't mean I had any idea WTF was going on though.\n\nAfter many test prints, head scratching and going through the files with a comb I finally noticed something. The files with the issue had `CRLF` (or `\\r\\n`) line endings. Those without (including my own sliced files) had just `LF` (or `\\n`) line endings.\n\nSo that made me go 🤨 Some cursing and breakpoint setting later I had proof that the reported progress in backend and frontend was flawed to begin with. I could see that a line was being reported with a file position that it actually was not located at in the file, and which instead belonged to a couple lines earlier. Which meant my positions were reported wrong right at the source -- with a lag. And then it suddenly hit me.\n\nBut before I can tell you what was happening I need to give you some background on how OctoPrint reads GCODE files it's printing in order to understand what was going on. Printed files are read line by line because that is how they are sent to the printer. For that OctoPrint uses the [`readline`](https://docs.python.org/3/library/io.html?highlight=readline#io.IOBase.readline) method of the file stream. And that works by reading chunks of data from the file until a line separator is found, returning everything read up to this separator and saving the rest for the next line to be read. That means the file will have to be read further than what is returned. And that means that the position in the open file as reported by [`tell`](https://docs.python.org/3/library/io.html?highlight=readline#io.IOBase.tell) on the file stream will always be slightly ahead. For progress reporting in OctoPrint however I need to know the exact byte position of each line in the file. So what I do instead of relying on the internal and slightly ahead file position is that I increase my own position indicator by the length of the line read from the file. And this is where my problem was located. \n\nIt turns out that for some reason I wasn't getting the lines back from `readline` with the original line endings attached. Instead I always got `LF`, even for files with `CRLF`. And that means I was counting one byte short for every single line in `CRLF` terminated files. One byte short per line doesn't sound like much, but that adds up through a file with several hundred thousands of lines, to a point where progress reporting will be off by whole layers the further in the print and thus the file you are.\n\nBut what was the reason for this popping up in 1.4.0? I hadn't modified the code in question at all. It had been the same since 2016 actually. Well, it turns out that a tiny change during the Python 3 compatibility migration done to a helper function I used in that code had interesting side effects: switching from [`codecs.open`](https://docs.python.org/3/library/codecs.html#codecs.open) to [`io.open`](https://docs.python.org/3/library/io.html#io.open). \n\nIt turns out that `io.open` (and thus Python 3's built-in `open`) by default will open text files in \"universal newlines mode\" (see [PEP278](https://www.python.org/dev/peps/pep-0278/)), meaning it will happily parse every common line ending, but convert it to `LF` before returning. Which caused my off-by-one issue in files with `CRLF`.\n\nAnd the fix? [Setting `newline=\"\"` on the open call](https://github.com/foosel/OctoPrint/commit/27bbab9582eb3a1a9fca8f2b203e88b1682fcdc5): \n\n``` diff\ndiff --git a/src/octoprint/util/comm.py b/src/octoprint/util/comm.py\nindex 67191a7af..a6dfc1e24 100644\n--- a/src/octoprint/util/comm.py\n+++ b/src/octoprint/util/comm.py\n@@ -4078,7 +4078,7 @@ def start(self):\n \t\t\"\"\"\n \t\tPrintingFileInformation.start(self)\n \t\twith self._handle_mutex:\n-\t\t\tself._handle = bom_aware_open(self._filename, encoding=\"utf-8\", errors=\"replace\")\n+\t\t\tself._handle = bom_aware_open(self._filename, encoding=\"utf-8\", errors=\"replace\", newline=\"\")\n \t\t\tself._pos = self._handle.tell()\n \t\t\tif self._handle.encoding.endswith(\"-sig\"):\n \t\t\t\t# Apparently we found an utf-8 bom in the file.\n```\n\nThe moral of the story? Don't trust your file position calculations. I could have saved myself a lot of time on debugging this if I had just looked there *first* instead of assuming this code to be fine 😅\n\nIn the end, even a year later, I still have no idea why Cura produced `CRLF` code for some and `LF` for me, but I also never really looked hard. A UNIX vs Windows issue can be ruled out here since the affected parties and me were all using Windows. It made me learn something about `io.open` and was a valuable lesson on wrong assumptions however!","excerpt":"","published":"2021-03-19T00:00:00Z","readingtime":{"text":"7 min read","minutes":6.035,"time":362100,"words":1207}},{"slug":"2021-03-13-my-workplace","title":"My workplace setup","subtitle":"How I try to keep backpain and RSI at bay","image":{"url":"/assets/content/blog/2021-03-13-my-workplace/office.jpg","alt":"My workplace - three monitors, desk, chair, keyboard, mouse, trackball","external":"https://foosel.net/assets/content/blog/2021-03-13-my-workplace/office.jpg"},"content":"\nI've been working full time from my home office since mid-2014 now. At the time of writing this post this is nearing 7 years. Naturally, considering how much time I spend there, I've also spent a lot of thought and money on making sure my workplace helps to keep the usual side effects of the mostly sedentary lifestyle of a developer at bay.\n\nOver the years I've had some run ins with RSI and backpain. My first wrist issues developed more than 10 years ago. Pain in my lower back beyond \"all fine again after a good night's sleep\" started in February of 2014. Both have been repeating visitors since then. You can probably imagine that that has led to a lot of research and experimentation to see what works and what doesn't for me. So, here's a summary of my findings as of March 2021. Quick disclaimer though, this is what has proven to work for **me**, that doesn't mean it will work for you, if in doubt please consult a professional. Also, I do link to some products here -- consider those references to give you more details on my setup, not official endorsement or anything like that.\n\n## Keyboard and mouse\n\nFor my wrists, **ergonomic keyboards** have proven to be crucial in combating the dreaded pain and numbness. I started with a [Microsoft Natural Ergonomic Keyboard 4000](https://www.microsoft.com/en-us/p/natural-ergonomic-keyboard-4000/) (what a name...), switched over to an [Microsoft Ergo Sculpt](https://www.microsoft.com/en-us/p/microsoft-sculpt-ergonomic-desktop/), had a quick detour over a regularly shaped [Ducky One TKL](https://www.duckychannel.com.tw/en/Ducky-One-RGB-TKL) to get my feet wet in mechanical keyboards and these days have arrived at the 1st gen [Ultimate Hacking Keyboard](https://ultimatehackingkeyboard.com/). It's a mechanical split keybord, sized at 60% (which means it has less keys than your common 101-key keyboard, only 60% of them to be precise, and compensates for that with the use of layers reached through modified keys) and fully programmable. I'm still optimizing the macros I have configured on it. I got it with red switches (linear and non clicky, I can't stand keyboards I can't use while holding a conversation ;)) and put a Git-themed keyset on it which I absolutely adore. And it's finally made me switch to US ANSI layout, which indeed is way better suited for coding than ISO DE. The UHK also supports some additional modules, and I have a trackpoint and an additional thumb keycluster on order once they finally release.\n\n![Closeup of my Ultimate Hacking Keyboard](./keyboard.jpg)\n\nNo matter how good you can memorize keyboard shortcuts (or how well the mouse layer of the UHK works), you still also need a **mouse**. In my case that's been gaming mice exclusively for 15+ years now, with a ton of turnover due to wear out or quality issues. Currently I'm sporting a [Steelseries Rival 310](https://steelseries.com/gaming-mice/rival-310) after my last mouse, a Roccat Kone XTD, developed a flaky mouse wheel I couldn't fix, even though I tried my best. Apparently a design flaw. The Steelseries has so far worked nicely, but I've only had it for less than six months at the time of writing this. It's an asymmetric mouse tailored for use with the right hand. I can reach the side buttons easily and it isn't too heavy or too light either.\n\nI also have a **trackball** though, dedicated to be used with my _left_ hand. Whenever I notice my right wrist acting up, I switch to exclusive trackball use for a while, and that has managed to still avert Bad Things a number of times now. If you find yourself regularly suffering from RSI issues on your mouse hand, I can really recommend to mix things up with a trackball on your left. Personally I got a [Kensington Slimblade](https://www.kensington.com/p/products/electronic-control-solutions/trackball-products/slimblade-trackball/). It's symmetrical and the buttons are easily remapped to fit a left hand operation. And the huge ball can also be used as a scrollwheel and is actually also a great fidget toy to have on the desk at all times ;)\n\n## Desk and chair\n\nIn my opinion, there are two pieces of furniture you should never cheap out on: your **office chair** and your bed. I bought my [sedus netwin](https://www.sedus.com/en/products/chairs/netwin) office chair right after finishing university in 2007 and apart from having gotten a bit more dirty here and there it's as good as new. I initially got it with a set of arm rests, but quickly figured out that those were actually detrimental to my posture and made me pull my shoulders up, leading to tension related pain. So I removed them. I've also gotten it a bit more pronounced lumbar support through the aid of [an add-on](https://www.amazon.de/gp/product/B07PB7G3QJ/), the likes of which you can order online for less than 10€ a piece. If I were to buy a new chair today, I'd probably get one with a head rest to keep me a bit more from slouching during long debugging or gaming sessions, but all in all I'm still completely happy with it, and the mesh back has proven to make sitting on it on hot summer days more bearable.\n\n![My office chair, with a lumbar support addon](./chair.jpg)\n\nI've now had an **electric standing desk** since January 2016. I'm currently trying to get into the habit of daily use of the standing mode again and so far it's looking good. I got the [IKEA Bekant](https://www.ikea.com/de/de/p/bekant-schreibtisch-sitz-steh-weiss-s69022537/) desk, and have since modified it to use the alternative [Megadesk](https://github.com/gcormier/megadesk) controller to give it position memory slots (and hopefully also to hook it up into my home automation system long term). I can't stress enough what a difference it can make to just stand for a while during your work day. Exclusively standing should definitely also be avoided (I've had to do this recently for a couple of days because my back would _not_ take sitting for an answer anymore, and it did a bit of a number on my ankles and knees), but regularly switching between sitting and standing is a great way not only to keep your posture intact but also to just get back your concentration. I currently work sitting until my lunch break, then switch to a couple hours of standing before either returning to sitting or calling it a day.\n\nSpeaking of sitting and standing -- I also recently acquired a bunch of accessories to make that more dynamic. While standing, I now regularly plant my feet on a **balance board** (a [Gymba](https://www.my-gymba.de/en) one in my case). It allows me to move while standing, to vary my stance more easily and frankly, it's also a ton of fun to seesaw back and forth while working. I use it with shoes - you can also use it barefoot/in socks, but frankly that was a bit to tough a surface or my feet. Your mileage may vary of course.\n\nI also got myself a **wobble stool** from [Flexispot](https://www.flexispot.com/height-adjustable-wobble-stool-bh1b). Imagine a stool, but instead of being stable it has a rounded base that makes it constantly wobble around. You cannot easily slouch on that, you'll fall over. Mine can be height adjusted from 61 to 82cm, so I use it both while standing as a small break, but also while sitting. I'm still getting used to it and am experimenting with heights and best way to sit on it, but it's so far been a great addition and doesn't take up much space (a serious plus in my limited office space).\n\n## Monitor mounts\n\nLast but not least, I've got my two main monitors mounted on a **dual monitor mount**, in my case a [gas lift one from PureMounts](http://www.puremounts.de/pm-office-dm-23d.html) (the small third monitor is mounted to the second one with a self designed printed mounting solution). The stands usually included with monitors tend to not offer enough flexibility to truly dial in the position of the screen in my experience, and this also managed to free up a _ton_ of desktop real estate that I can now utilize. In my case, a wallmount is not an option due to the standing desk situation, so I instead went for a desk mount. A gas lift is not the most stable option in my experience: things can be a bit shaky when I accidentally bump against the desk due to the rather extreme lever position I had to chose to make things work in my office, but it has been working just fine now since 2012. Still, at some point I might get something a bit more static. In any case, a monitor mount is something I'd highly recommended for everyone really, even if you don't want if for ergonomic reasons -- I cannot emphasize the increase in desk space enough ;)\n\n![My monitors, mounted on a gas lift mount](./monitors.jpg)\n\n## tl;dr\n\nGet a split ergo keyboard, a gaming mouse for your primary and a trackball for your off hand. Don't cheap out on your office chair, seriously consider investment in a standing desk, get a balance board with it and finally reclaim your desk and improve your workplace's ergonomy at the same time with a monitor mount.\n","excerpt":"","published":"2021-03-13T00:00:00Z","readingtime":{"text":"8 min read","minutes":7.515,"time":450900,"words":1503}},{"slug":"2021-03-12-hello-world","published":"2021-03-12T23:00:00+0100","title":"Hello World!","subtitle":"The long overdue foosel.net reboot","image":{"url":"/assets/content/blog/2021-03-12-hello-world/new_start.jpg","alt":"The autumn sun seen through some trees, with the bottom covered in leaves","external":"https://foosel.net/assets/content/blog/2021-03-12-hello-world/new_start.jpg"},"content":"\nIt's been a couple years since I last tried to maintain a blog. Back then I was still living life as a corporate drone,\nemployed as a Software Architect to consult other people on their IT problems. I rarely had anything I could blog about\n-- either things were under NDA, or they were simply uninteresting. Since then my life has been turned completely on its head.\nIn late 2012 I got myself a 3d printer, spent my Christmas break to develop a small web interface for it, that grew into a full\nsized Open Source project called [OctoPrint](https://octoprint.org) and these days I work full time on it.\n\nI've learned a lot not only on 3d printers & Python, but also on Open Source development, crowdfunding, the challenges of\ncommunity management, but also on work life balance, workplace ergonomics, home office life and stress management. And that's\njust from my job! In my personal life I've also spent a lot of time tinkering with electronics, learned how to bake bread,\ndiscovered cooking and went completely down the home automation rabbit hole.\n\nI don't know about you, but I think that should hopefully make for some good opportunities to blog again, and save some of\nmy learnings in a more persistent way than the ephemeral nature of twitter threads. So I did what apparently every dev seems\nto do in such a case and spent way too much time on a webpage reboot with some new tooling that I wanted to try anyway,\nand this is the result. This whole page is still a static page, but I've switched it from [Jekyll](https://jekyllrb.com)\nto [next.js](https://nextjs.org/). Why? I wanted to get some more hands-on experience with React since I'm evaluating it for a\nnew UI for OctoPrint, and I also never really warmed up to Ruby but know JS, so with expandability in mind this just feels like a\nbetter fit. If you want to study the source, you can find that [here](https://github.com/foosel/foosel.github.io) (but please\ndon't look too closely, I'm still learning and things are probably not even remotely optimally implemented).\n\nSo here we are, and it's time to fill this up a bit more. Thankfully I already got some ideas...\n","excerpt":"","readingtime":{"text":"2 min read","minutes":1.84,"time":110400,"words":368}}],"previous":null},"__N_SSG":true}